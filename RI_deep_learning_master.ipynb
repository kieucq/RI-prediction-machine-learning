{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "311c26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: This script provides an RI prediction workflow based on 3 deep learning algorithms\n",
    "#       that treat RI as yes/no (1/0) event. The workflow requires SHIP input predictors\n",
    "#       from HWRF/HAFS forecasts from 0h to 24h lead time as an input.\n",
    "#\n",
    "#       To run in a job submission mode, use a Python script RI_deep_learning_master.py, \n",
    "#       which is generated directly from this Jupyter notebook. \n",
    "#\n",
    "#       For more operational process, use 2 Python scripts RI_deep_learning_build.py\n",
    "#       for training models, and RI_deep_learning_prediction.py for predicting step. These\n",
    "#       two Python scripts should also be identical to this Jupyter notebook script, \n",
    "#       except that the testing step is splitted and no visualization of the training can \n",
    "#       be seen.\n",
    "#\n",
    "#       To add new DL models, edit the module file RI_deep_learning_libmodel.py\n",
    "#\n",
    "# HIST: - 10, Mar 2023: created by CK\n",
    "#       - 02, Nov 2023: CK updated the input data for consistency of header information \n",
    "#                       between training and real-time dataframes. \n",
    "#       - 03, Nov 2023: CK re-worked on the flow to have both 00h and 24h predictors input\n",
    "#\n",
    "# AUTH: Chanh Kieu (ckieu@indiana.edu)\n",
    "#===========================================================================================\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import RI_deep_learning_libmodel as RImodel\n",
    "import RI_deep_learning_libutils as RIutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe18bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# reading all input data, and replace/remove bad data. Note that \n",
    "# - this data set must contain the last column \"class\" indicating RI (1) or non-RI (0). \n",
    "# - option flag_input_more_time must be 00h or 24h to indicate a single time slice, or \n",
    "#   mutiple time slices from SHIP forecasts.\n",
    "# - A list of 16 vars to be removed must be consistent between models and prediction \n",
    "#   script. That is, var_to_remove must be set as one of the folliwng 17 variables\n",
    "#   var_to_remove = ['OHC','LAT','LON','MAXWIND','RMW','MIN_SLP','SHR_MAG','SHR_HDG',\n",
    "#                    'STM_SPD','STM_HDG','SST','TPW','LAND','850TANG','850VORT','200DVRG']                   \n",
    "#\n",
    "debug = 0                       # debug printing level (0 or 1)\n",
    "visualization = \"no\"            # displays the training history (yes or no). \n",
    "flag_input_future_time=\"24h\"    # SHIP predictors input option (00h or 24h)\n",
    "metric_threshold = 0.7          # binary accuracy threshold for training (0-1)\n",
    "split_ratio = 0.05              # slit ratio between training/validation (0-1)\n",
    "var_to_remove = ['OHC']         # list of vars to be removed. See the complete list above \n",
    "infile='/N/u/ckieu/BigRed200/model/RI-prediction/SHIP_allbasin_2011_2022_Version4.csv'\n",
    "df = RIutils.filterdata(infile,flag_input_future_time,var_to_remove)\n",
    "if debug == 1: \n",
    "    print(\"The length of data frame df variable is \",len(df))\n",
    "    print(\"The top 3 samples of the dataframe df are:\")\n",
    "    print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdadb5c0-f603-447a-9150-c6c568a5e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# split (x,y) pair based on the lass col \"class\"\n",
    "#\n",
    "x = np.array(df.drop(['class'],axis=1)).astype(\"float32\")\n",
    "y = np.array(df['class']).astype(\"float32\")\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x, y, test_size=split_ratio,shuffle=True)\n",
    "validation_split = int(split_ratio*len(x1_train))\n",
    "x2_val = x1_train[:validation_split]\n",
    "y2_val = y1_train[:validation_split]\n",
    "x2_train = x1_train[validation_split:]\n",
    "y2_train = y1_train[validation_split:]\n",
    "if debug == 1:\n",
    "    print(x[0],y[0])\n",
    "    print(\"Total train and test data sizes are: \", x1_train.shape,x1_test.shape,y1_train.shape,y1_test.shape)\n",
    "    print(\"Validation split is \",validation_split)\n",
    "    print(\"Train and validation data sizes are: \", x2_train.shape,x2_val.shape,y2_train.shape,y2_val.shape)\n",
    "    #print(x2_val[0].astype('int'),y2_val[0].astype('int'))\n",
    "    #print(x1_train[385].astype('int'),y1_train[385].astype('int'))\n",
    "    #print(x2_train[0].astype('int'),y2_train[0].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3106e5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Build a logistic model with options model_logistics32 or model_logistics64\n",
    "#\n",
    "model_logistics = RImodel.model_logistics32(metric_threshold=metric_threshold)\n",
    "bestmodel_name = \"RI_model_logistics_\"+flag_input_future_time+\".keras\"\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(bestmodel_name,save_best_only=True)]\n",
    "history_logistics = model_logistics.fit(x2_train,y2_train,epochs=100,batch_size=16,\n",
    "                                       validation_data=(x2_val,y2_val),callbacks=callbacks,verbose=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68f5fc90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# check F1 score for the logistic model with the internal test data\n",
    "#\n",
    "if debug == 1:\n",
    "    results = model_logistics.evaluate(x1_test,y1_test,verbose=debug)\n",
    "    single_fcst = model_logistics.predict(x1_test,verbose=debug)\n",
    "    #for i in range(len(single_fcst)):\n",
    "    #    print(y1_test[i],\" <---> RI Propbability: \",f\"{float(single_fcst[i]):.5f}\")\n",
    "    print(\"Evalution results (loss,accuracy) for the test data is \",results)\n",
    "    print(\"F1, Recall, Precision for logistic model are:\",RIutils.F1_score(y1_test,single_fcst,1,0.10))  \n",
    "#\n",
    "# plotting the performance of the logistics regression\n",
    "#\n",
    "if visualization == \"yes\":\n",
    "    RIutils.visualization_logistics(history_logistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e2e5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create input data for RNN by reshaping the input data into a new tensor of the dimension\n",
    "# (num_sample, num_times, num_predictors). Note that using the metric=accuracy returns very bad\n",
    "# accuracy < 0.1\n",
    "# \n",
    "if flag_input_future_time == \"24h\":\n",
    "    sequence_length = 5\n",
    "elif flag_input_future_time == \"12h\":\n",
    "    sequence_length = 3\n",
    "elif flag_input_future_time == \"00h\":\n",
    "    sequence_length = 1    \n",
    "num_predictors = 16 - len(var_to_remove)\n",
    "x3_val = x2_val.reshape((-1,sequence_length,num_predictors))\n",
    "x3_train = x2_train.reshape((-1,sequence_length,num_predictors))\n",
    "test_dataset = x1_test.reshape((-1,sequence_length,num_predictors))\n",
    "if debug == 1:\n",
    "    print(\"Train/val data sizes before reshape are: \", x2_train.shape,x2_val.shape,y2_train.shape,y2_val.shape)\n",
    "    print(\"New train/validation data sizes for RNN are: \", x3_train.shape,x3_val.shape, test_dataset.shape)\n",
    "    print(x2_val[0])\n",
    "    print(x3_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21042f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Build a RNN model with options model_RNN16 or model_RNN32\n",
    "#\n",
    "model_RNN = RImodel.model_RNN32(sequence_length,num_predictors,metric_threshold=metric_threshold)\n",
    "bestmodel_name = \"RI_model_RNN_\"+flag_input_future_time+\".keras\"\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(bestmodel_name,save_best_only=True)]\n",
    "history_RNN = model_RNN.fit(x3_train, y2_train, epochs=100, batch_size=64, \n",
    "                            validation_data=(x3_val, y2_val), callbacks=callbacks,verbose=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19578e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check F1 score now for the RNN model\n",
    "#\n",
    "if debug == 1:\n",
    "    model_best = keras.models.load_model(bestmodel_name)\n",
    "    print(f\"The best trained RNN prediction error is: {model_best.evaluate(test_dataset,y1_test,verbose=debug)[1]:.3f}\")\n",
    "    print(f\"The last trained RNN prediction error is: {model_RNN.evaluate(test_dataset,y1_test,verbose=debug)[1]:.3f}\")\n",
    "    y_prediction = model_RNN.predict(test_dataset)\n",
    "    print(\"F1, Recall, Precision for RNN model are:\",RIutils.F1_score(y1_test,y_prediction,1,0.1))\n",
    "#\n",
    "# plotting the performance of the logistics regression\n",
    "#\n",
    "if visualization == \"yes\":\n",
    "    RIutils.visualization_RNN(history_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc307d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Build GRU model with options model_GRU16 or model_GRU32\n",
    "#\n",
    "model_GRU = RImodel.model_GRU32(sequence_length,num_predictors,metric_threshold=metric_threshold)\n",
    "bestmodel_name = \"RI_model_GRU_\"+flag_input_future_time+\".keras\"\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(bestmodel_name,save_best_only=True)]\n",
    "history_GRU = model_GRU.fit(x3_train, y2_train, epochs=100, batch_size=64, \n",
    "                             validation_data=(x3_val, y2_val), callbacks=callbacks,verbose=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb8e1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check F1 score now for the GRU model\n",
    "#\n",
    "if debug == 1:\n",
    "    model_best = keras.models.load_model(bestmodel_name)\n",
    "    print(f\"The best trained GRU prediction error is: {model_best.evaluate(test_dataset,y1_test,verbose=debug)[1]:.3f}\")\n",
    "    print(f\"The last trained GRU prediction error is: {model_GRU.evaluate(test_dataset,y1_test,verbose=debug)[1]:.3f}\")\n",
    "    y_prediction = model_GRU.predict(test_dataset)\n",
    "    print(\"F1, Recall, Precision for GRU model are:\",RIutils.F1_score(y1_test,y_prediction,1,0.1))\n",
    "#\n",
    "# plotting the performance of the logistics regression\n",
    "#\n",
    "if visualization == \"yes\":\n",
    "    RIutils.visualization_GRU(history_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e48718a-2e0d-48cb-b702-1093834273d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# reading a single case of a TC now for testing\n",
    "#\n",
    "testfile=\"/N/u/ckieu/BigRed200/model/RI-prediction/OTIS18E_master.csv\"\n",
    "df = RIutils.filterdata(testfile,flag_input_future_time,var_to_remove)\n",
    "x_fcst = np.array(df.drop(['class'],axis=1))\n",
    "y_true = np.array(df['class'])\n",
    "x_tlag = x_fcst.reshape((-1,sequence_length,num_predictors))\n",
    "if debug == 1:\n",
    "    print('External input SHIP data length is: ',len(x_fcst))\n",
    "    print('RI record for this storm is: ',y_true)\n",
    "    print('Reshape for RNN and GRU input is: ',x_tlag.shape)\n",
    "    print(x_fcst[0].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72cfd80f-dc7e-4dd0-9578-b62f3cc231cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14992552b010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14992552b5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Logistic, RNN, GRU probability predictions: 0.132,0.189,0.041\n",
      "Logistic, RNN, GRU probability predictions: 0.098,0.226,0.041\n",
      "Logistic, RNN, GRU probability predictions: 0.090,0.507,0.041\n",
      "Logistic, RNN, GRU probability predictions: 0.013,0.269,0.068\n",
      "Logistic, RNN, GRU probability predictions: 0.056,0.118,0.061\n",
      "Logistic, RNN, GRU probability predictions: 0.035,0.040,0.023\n",
      "Logistic, RNN, GRU probability predictions: 0.008,0.013,0.007\n",
      "Logistic, RNN, GRU probability predictions: 0.003,0.008,0.026\n",
      "Logistic, RNN, GRU probability predictions: 0.000,0.004,0.033\n",
      "Logistic, RNN, GRU probability predictions: 0.000,0.110,0.041\n",
      "Logistic, RNN, GRU probability predictions: 0.000,0.016,0.026\n",
      "Logistic, RNN, GRU probability predictions: 0.000,0.202,0.250\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Make prediction of RI for the single case (all cycles)\n",
    "#\n",
    "model_RNN = keras.models.load_model(\"RI_model_RNN_\"+flag_input_future_time+\".keras\")\n",
    "model_logistics = keras.models.load_model(\"RI_model_logistics_\"+flag_input_future_time+\".keras\")\n",
    "model_GRU = keras.models.load_model(\"RI_model_GRU_\"+flag_input_future_time+\".keras\")\n",
    "\n",
    "fcst_logistics = model_logistics.predict(x_fcst,verbose=debug)\n",
    "fcst_GRU = model_GRU.predict(x_tlag,verbose=debug)\n",
    "fcst_RNN = model_RNN.predict(x_tlag,verbose=debug)\n",
    "for i in range(len(x_fcst)):\n",
    "   print(f\"Logistic, RNN, GRU probability predictions: {float(fcst_logistics[i]):.3f},{float(fcst_RNN[i]):.3f},{float(fcst_GRU[i]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "333f6362-106f-4518-bdad-a8d252da04fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1, Recall, Precision for logistics model with 24h data are: (0.0, 0.0, 0.0)\n",
      "F1, Recall, Precision for RNN model with 24h data are: (0.18181818181818182, 0.25, 0.14285714285714285)\n",
      "F1, Recall, Precision for GRU model with 24h data are: (0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"F1, Recall, Precision for logistics model with \"+flag_input_future_time+\" data are:\",RIutils.F1_score(y_true,fcst_logistics,1,0.1))\n",
    "print(\"F1, Recall, Precision for RNN model with \"+flag_input_future_time+\" data are:\",RIutils.F1_score(y_true,fcst_RNN,1,0.1))\n",
    "print(\"F1, Recall, Precision for GRU model with \"+flag_input_future_time+\" data are:\",RIutils.F1_score(y_true,fcst_GRU,1,0.1))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
